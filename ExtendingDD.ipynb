{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961c370f",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d45ce",
   "metadata": {},
   "source": [
    "In this tutorial, we will explain the basics of extending Data Detective to new data types, new validator methods, new validators, and new transforms. We will build up to performing anomaly detection on the MNIST dataset using PCA anomaly scoring.\n",
    "\n",
    "Prerequisites include all of the information in the Data Detective Basics tutorial.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade torchvision\n",
    "!pip install --upgrade pyod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1139eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyod\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import typing\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from typing import Dict, Union, Set, Type\n",
    "\n",
    "from constants import FloatTensor\n",
    "from src.aggregation.rankings import RankingAggregator, RankingAggregationMethod\n",
    "from src.data_detective_engine import DataDetectiveEngine\n",
    "from src.enums.enums import DataType, ValidatorMethodParameter\n",
    "from src.validators.data_validator import DataValidator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfa30b",
   "metadata": {},
   "source": [
    "# Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 50 \n",
    "\n",
    "class TutorialDataset(MNIST):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        dataset_size = self.__len__()\n",
    "    \n",
    "    def __getitem__(self, idx: Union[int, slice, list]) -> Dict[str, Union[FloatTensor, int]]:\n",
    "        \"\"\"\n",
    "        Returns a dictionary of the image, vector, and label. \n",
    "        \"\"\"\n",
    "        sample = super().__getitem__(idx)\n",
    "        return {\n",
    "            \"mnist_image\": sample[0],\n",
    "            \"label\": sample[1],\n",
    "        }\n",
    "    \n",
    "    #TODO: remove\n",
    "    def __len__(self) -> int: \n",
    "        return DATASET_SIZE\n",
    "\n",
    "    def datatypes(self) -> Dict[str, DataType]:\n",
    "        return {\n",
    "            \"mnist_image\": DataType.IMAGE,\n",
    "            \"label\": DataType.CATEGORICAL,\n",
    "        }\n",
    "    \n",
    "    def show_datapoint(self, idx: int):\n",
    "        \"\"\"\n",
    "        Shows data point from tutorial.\n",
    "        \"\"\"\n",
    "        # src: https://stackoverflow.com/questions/31556446/how-to-draw-axis-in-the-middle-of-the-figure\n",
    "        sample = self[idx]\n",
    "        print(sample[\"label\"])\n",
    "        plt.imshow(sample[\"mnist_image\"].squeeze())\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "dataset = TutorialDataset(\n",
    "    root='./data/MNIST',\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848a420b",
   "metadata": {},
   "source": [
    "# Creating a Validator Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b079a2",
   "metadata": {},
   "source": [
    "## The Structure of Validator Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87def2d",
   "metadata": {},
   "source": [
    "Each validator method is a static class that has 4 static, functional methods:\n",
    "1. The `datatype` method, which returns a set of datatypes that are supported by the validator method. \n",
    "<!---The set is considered an \"OR\" relation (that is, if any of of the datatypes in the set are present in the dataset, the validator method will be applied). --->\n",
    "2. The `param_keys` method, which returns a set containinng the data splits that the method applies to. \n",
    "3. The `validate` method, which returns some type of actionable result. \n",
    "4. The `get_method_kwargs` method, which takes in the data object and validator kwargs and sets up the calls to `validate`. \n",
    "\n",
    "Let's go through a simple validator method and examine all of these components. The example validator method that we will be examining determines the principle components of a multidimensional column over a dataset and uses reconstruction error over the fitted principle components to provide an anomaly score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfcf64b",
   "metadata": {},
   "source": [
    "## Example: PCA Anomaly Validator Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb78378f",
   "metadata": {},
   "source": [
    "The first step in writing a new validator method is creating a good test for the validator method using synthetic data. Tests are a crucial part of the data detective validator method construction process for three reasons: \n",
    "1. They are helpful early on in the design process for considering and enforcing sensible top-down interface decisions.\n",
    "2. They are a useful piece of documentation to both yourself as you write the method and to an end user in understanding how to use your method.\n",
    "3. They verify correctness of your implementation. \n",
    "\n",
    "For our example, we will be constructing a 10-dimensional synthetic normal dataset with 99% of samples drawn from N(μ=0, σ=1) and 1% of samples drawn from N(μ=10, σ=1). In order to examine correctness, we will look at the AUCRoC scores between the true anomaly labels and the incorrect anomaly labels. The test that we will be using is shown below. [TODO: write test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa3941",
   "metadata": {},
   "source": [
    "### 1. `datatype()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f37e536",
   "metadata": {},
   "source": [
    "We would like our PCA method to take in only multidimensional data, so let's specify that in the `datatype()` method. We specify this by returning a set of `DataType` objects. If we had wanted to start extending support to new datatypes, we would at this point extend the `DataType` enumeration and specify the new data type in the `datatype` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datatype() -> Set[DataType]:\n",
    "    \"\"\"\n",
    "    @return: the datatype the validators method operates on.\n",
    "    \"\"\"\n",
    "    return { DataType.MULTIDIMENSIONAL }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f08db",
   "metadata": {},
   "source": [
    "### 2. `param_keys()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7085b",
   "metadata": {},
   "source": [
    "PCA Anomaly validation is an unsupervised method, so it needs to take in the entire dataset to fit/evaluate the model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec0719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_keys() -> Set[ValidatorMethodParameter]:\n",
    "    \"\"\"\n",
    "    Lists the data splits that the validators operates on.\n",
    "    \n",
    "    @return: a set of data splits for the .validate() method.\n",
    "    \"\"\"\n",
    "    return { ValidatorMethodParameter.ENTIRE_SET }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc5345",
   "metadata": {},
   "source": [
    "### 3. `validate()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba1fc7a",
   "metadata": {},
   "source": [
    "Our `validate()` method will map us from some representation of the data to a single result. For the PCA `validate()` method, let's choose to take in the entire n x d data matrix for a given column of data and an option indicating the number of components to keep for computation of outlier scores. In the method body, we will fit an existing PCA anomaly detection method from `pyod` and use that model to give us a set of anomaly scores based on reconstruction loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75981c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    data_matrix: Type[np.array] = None, # n x d data matrix for a givenn column\n",
    "    n_components=None,\n",
    ") -> object:\n",
    "    \"\"\"\n",
    "    Runs PCA anomaly detection.\n",
    "\n",
    "    @return: a list of n scores, one per sample. \n",
    "    \"\"\"\n",
    "    model = pyod.models.pca.PCA(n_components=n_components)\n",
    "    model.fit(data_matrix)\n",
    "\n",
    "    anomaly_scores = model.decision_function(data_matrix)\n",
    "\n",
    "    return anomaly_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43695655",
   "metadata": {},
   "source": [
    "### 4. `get_method_kwargs()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e5a03d",
   "metadata": {},
   "source": [
    "In the `get_method_kwargs()` method, we will be taking the set of options passed in the validation schema as well as the data object and setting up the calls to the `validate()` method. This method should return a dictionary where each value contains the kwargs for a `validate()` call and each key reflects where the `validate()` call will store its results in the final method results dictionary. \n",
    "\n",
    "Every `get_method_kwargs()` method accepts two things: the validation schema and the data object. For our PCA anomaly example, we will want to perform one call for each entry in the data object, giving us a score for each column of each sample. \n",
    "\n",
    "<!--Every `get_method_kwargs()` method accepts two things: the validation schema and the (filtered) data object. The data object is preliminarily filtered in two ways: \n",
    "1. The `include` option in the validation schema accepts a list of regular expressions under each \n",
    "2. The `datatype()` method results in the data object being filtered to only include columns in that data object.-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910ab77b",
   "metadata": {},
   "source": [
    "First, we will include a helper method to get the data matrix from a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data_matrix_dict(dataset: torch.utils.data.Dataset = None) -> Dict[str, np.array]:\n",
    "    \"\"\"\n",
    "    Takes a dataset and returns a dictionary mapping from each column in the dataset to an n x d \n",
    "    numpy array, where n is the number of entries in the dataset and d is the column's dimension\n",
    "    in the dataset. \n",
    "        \n",
    "    @return: an n x d numpy array, where n is the number of entries in the dataset and d is the \n",
    "    column's dimension in the dataset. \n",
    "    \"\"\"\n",
    "    matrix_dict = {\n",
    "        column: [] for column in dataset.datatypes().keys()\n",
    "    }\n",
    "\n",
    "    for idx in range(dataset.__len__()):\n",
    "        sample = dataset[idx]\n",
    "        for column, column_data in sample.items():\n",
    "            matrix_dict[column].append(column_data)\n",
    "\n",
    "    for column in dataset.datatypes().keys():\n",
    "        matrix_dict[column] = np.vstack(matrix_dict[column])\n",
    "            \n",
    "    return matrix_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e81dd2",
   "metadata": {},
   "source": [
    "Now, let's use the above method to write our `get_method_kwargs()` function, which needs to retrieve our `data_matrix` and `n_components` parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_method_kwargs(data_object: Dict[str, torch.utils.data.Dataset], validator_kwargs: Dict = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Gets the arguments for each run of the validator_method, and what to store the results under.\n",
    "\n",
    "    @param data_object: the datasets object containing the datasets (train, test, entire, etc.)\n",
    "    @param validator_kwargs: the kwargs from the validation schema.\n",
    "    @return: a dict mapping from the key the result from calling .validate() on the kwargs values.\n",
    "    \"\"\"\n",
    "    entire_dataset: torch.utils.data.Dataset = data_object[\"entire_set\"]\n",
    "    matrix_dict = _get_data_matrix_dict(entire_dataset)\n",
    "        \n",
    "    kwargs_dict = {\n",
    "        f\"{column}_results\": {\n",
    "            \"data_matrix\": column_data,\n",
    "            \"n_components\": validator_kwargs.get(\"n_components\")\n",
    "                            # ^will default to None if n_components is not provided\n",
    "        } for column, column_data in matrix_dict.items()\n",
    "    }\n",
    "\n",
    "    return kwargs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793b317",
   "metadata": {},
   "source": [
    "Great! Let's wrap all of the methods we have written in a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1870a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from typing import Set, Dict, Type\n",
    "\n",
    "import numpy as np\n",
    "import pyod.models.pca\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from src.enums.enums import DataType, ValidatorMethodParameter\n",
    "from src.validator_methods.data_validator_method import DataValidatorMethod\n",
    "\n",
    "class MyPCAAnomalyValidatorMethod(DataValidatorMethod):\n",
    "    \"\"\"\n",
    "    A method for determining anomalies on multidimensional data. Operates on continuous datasets.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def name() -> str: \n",
    "        return \"my_pca_validator_method\"\n",
    "\n",
    "    @staticmethod\n",
    "    def datatype() -> Set[DataType]:\n",
    "        return datatype()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def param_keys() -> Set[ValidatorMethodParameter]:\n",
    "        \"\"\"\n",
    "        @return: a set of data splits for the data object to include.\n",
    "        \"\"\"\n",
    "        return param_keys()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_method_kwargs(data_object: typing.Dict[str, Dataset], validator_kwargs: Dict = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Gets the arguments for each run of the validator_method, and what to store the results under.\n",
    "\n",
    "        @param data_object: the datasets object containing the datasets (train, test, entire, etc.)\n",
    "        @param validator_kwargs: the kwargs from the validation schema.\n",
    "        @return: a dict mapping from the key the result from calling .validate() on the kwargs values.\n",
    "        \"\"\"\n",
    "        return get_method_kwargs(data_object, validator_kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def validate(\n",
    "        data_matrix: Type[np.array] = None, # n x d data matrix for a givenn column\n",
    "        n_components=None,\n",
    "    ) -> object:\n",
    "        \"\"\"\n",
    "        Runs PCA anomaly detection.\n",
    "\n",
    "        @return: a list of n scores, one per sample. \n",
    "        \"\"\"\n",
    "        return validate(data_matrix, n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2197dc",
   "metadata": {},
   "source": [
    "# Creating a Validator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be22c1",
   "metadata": {},
   "source": [
    "Validators are simply sets of validator methods. Creating a new one is relatively straightforward. They consist of the set of validator methods that they include as well as a `default` attribute indicating whether the validator should be included in all validation schemas. Let's create a non-default validator for our PCA anomaly method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbdc35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyUnsupervisedAnomalyDataValidator(DataValidator):\n",
    "    \"\"\"\n",
    "    A dataset has many features/columns, and each column has many ValidatorMethods that apply to it, depending on the\n",
    "    datatype. A DataValidator is a collection of ValidatorMethods for a unique purpose.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def name() -> str: \n",
    "        return \"my_unsupervised_anomaly_data_validator\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_default():\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def validator_methods() -> Set[Type[DataValidatorMethod]]:\n",
    "        return {\n",
    "            MyPCAAnomalyValidatorMethod\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb84670",
   "metadata": {},
   "source": [
    "# Creating a Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1525d",
   "metadata": {},
   "source": [
    "There are two steps to creating a new transform: \n",
    "\n",
    "1. Creating a higher order transformation function\n",
    "2. Registering the new transform in the transform library. \n",
    "\n",
    "Let's look at an example of a simple transform that maps images to their ResNet50 embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transforms.embedding_transformer import Transform\n",
    "\n",
    "\n",
    "def get_resnet50(**kwargs):\n",
    "    import torchvision.models\n",
    "    resnet = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V2, **kwargs)\n",
    "    modules = list(resnet.children())[:-1]\n",
    "    backbone = torch.nn.Sequential(torch.nn.Upsample((224, 224)), *modules)\n",
    "    def full_impl(x):\n",
    "        if len(x.shape) == 3:\n",
    "            # need a 4th dimension\n",
    "            x = torch.unsqueeze(x, 0)\n",
    "        if x.shape[-3] == 1:\n",
    "            # need to map to multiple channels\n",
    "            x2 = torch.zeros((x.shape[0], 3, x.shape[2], x.shape[3]))\n",
    "            x2[:, 0, :, :] = x[:, 0, :, :]\n",
    "            x2[:, 1, :, :] = x[:, 0, :, :]\n",
    "            x2[:, 2, :, :] = x[:, 0, :, :]\n",
    "            x = x2\n",
    "\n",
    "        x = backbone(x)\n",
    "        x = x.squeeze()\n",
    "        x = x.reshape((-1, 2048))\n",
    "        x = x.detach().numpy()\n",
    "\n",
    "        return x\n",
    "\n",
    "    return full_impl\n",
    "\n",
    "my_resnet50_transform = Transform(\n",
    "        transform_class=get_resnet50,\n",
    "        new_column_name_fn=lambda name: f\"resnet50_backbone_{name}\",\n",
    "        new_column_datatype=DataType.MULTIDIMENSIONAL\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b359c",
   "metadata": {},
   "source": [
    "There are a few patterns worth noting in the above implementation. The `get_{transform}` higher order function always takes in kwargs that are passed through from the `options` parameter of the input transforms. \n",
    "\n",
    "The most important is the use of an inner helper function (in this case, `full_impl`) that is returned. Returning an inner function allows for one-time initialization of the backbone and of the parsing of options in kwargs. \n",
    "\n",
    "Now that we have our higher order transformation function, let's add it to the transform library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d911168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transforms.embedding_transformer import Transform\n",
    "\n",
    "TRANSFORM_LIBRARY = {\n",
    "    # our new lovely transform!\n",
    "    \"resnet50\": Transform(\n",
    "        transform_class=get_resnet50,\n",
    "        new_column_name_fn=lambda name: f\"resnet50_backbone_{name}\",\n",
    "        new_column_datatype=DataType.MULTIDIMENSIONAL\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05928cc",
   "metadata": {},
   "source": [
    "Great! We have successfully added the transform to the transform library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: this is what we want the implementation of the data_detective_engine to look like. \n",
    "# we need to parse this into two tutorials: one for contributions to the existing codebase, and one for modular extensions.\n",
    "\n",
    "data_detective_engine = DataDetectiveEngine()\n",
    "\n",
    "data_detective_engine.register_validator(MyUnsupervisedAnomalyDataValidator)\n",
    "data_detective_engine.register_transform(my_resnet50_transform, \"my_resnet50\")\n",
    "\n",
    "validation_schema = {\n",
    "    \"default_inclusion\": False,\n",
    "    \"validators\": {\n",
    "        \"my_unsupervised_anomaly_data_validator\": {},\n",
    "    },\n",
    "    \"transforms\": {\n",
    "        \"image\": [{\n",
    "            \"name\": \"my_resnet50\",\n",
    "            \"in_place\": \"False\",\n",
    "            \"options\": {},\n",
    "        }],\n",
    "    }\n",
    "}\n",
    "\n",
    "data_object = {\n",
    "    \"entire_set\": dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3611d3",
   "metadata": {},
   "source": [
    "# Running the Data Detective Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ecb162",
   "metadata": {},
   "source": [
    "Now that the full validation schema and data object are prepared, we are ready to run the Data Detective Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57946fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = data_detective_engine.validate_from_schema(validation_schema, data_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e1d58",
   "metadata": {},
   "source": [
    "Great! Let's start to look at and analyze the results we've collected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84578eae",
   "metadata": {},
   "source": [
    "# Interpreting Results using the Built-In Rank Aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0cbba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from typing import List\n",
    "\n",
    "from pyrankagg.rankagg import FullListRankAggregator\n",
    "\n",
    "class RankingAggregationMethod(Enum):\n",
    "    MEDIAN_AGGREGATION = \"median_aggregation\"\n",
    "    HIGHEST_RANK = \"highest_rank\"\n",
    "    LOWEST_RANK = \"lowest_rank\"\n",
    "    STABILITY_SELECTION = \"stability_selection\"\n",
    "    EXPONENTIAL_WEIGHTING = \"exponential_weighting\"\n",
    "    STABILITY_ENHANCED_BORDA = \"stability_enhanced_borda\"\n",
    "    EXPONENTIAL_ENHANCED_BORDA = \"exponential_enhanced_borda\"\n",
    "    ROBUST_AGGREGATION = \"robust_aggregation\"\n",
    "    ROUND_ROBIN = \"round_robin\"\n",
    "\n",
    "\n",
    "class RankingAggregator:\n",
    "    FLRA = FullListRankAggregator()\n",
    "\n",
    "    def __init__(self, results_object):\n",
    "        self.results_object = results_object\n",
    "\n",
    "    @staticmethod\n",
    "    def list_is_full_ranking(lst):\n",
    "        lst_len = len(lst)\n",
    "        return list(range(lst_len)) == sorted(lst)\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_scorelist(dataframe):\n",
    "        \"\"\" scorelist = [{'milk':1.4,'cheese':2.6,'eggs':1.2,'bread':3.0},\n",
    "                         {'milk':2.0,'cheese':3.2,'eggs':2.7,'bread':2.9},\n",
    "                         {'milk':2.7,'cheese':3.0,'eggs':2.5,'bread':3.5}]\"\"\"\n",
    "        scorelist = []\n",
    "        for col in dataframe.columns:\n",
    "            tmp_dict = {f\"item {idx}\": val for idx, val in zip(dataframe.index, dataframe[col])}\n",
    "            scorelist.append(tmp_dict)\n",
    "        return scorelist\n",
    "\n",
    "    @staticmethod\n",
    "    def get_rankings(scores):\n",
    "        return {f\"item {k}\": v for k, v in RankingAggregator.FLRA.convert_to_ranks(dict(enumerate(scores))).items()}\n",
    "\n",
    "    def construct_rankings_df(self, validator_name, given_validator_method: str = None, given_data_modality: str = None):\n",
    "        validator_results = self.results_object[validator_name]\n",
    "        results_obj = {}\n",
    "\n",
    "        for validator_method, results_dict in validator_results.items():\n",
    "            if given_validator_method and (validator_method != given_validator_method):\n",
    "                continue\n",
    "            for data_modality, scores in results_dict.items():\n",
    "                if given_data_modality and (data_modality.replace(\"_results\", \"\") != given_data_modality):\n",
    "                    continue\n",
    "                rankings = RankingAggregator.get_rankings(scores)\n",
    "                results_obj[f\"{data_modality}_{validator_method}_rank\"] = rankings\n",
    "        \n",
    "        rankings_df = pd.DataFrame(results_obj)\n",
    "        return rankings_df.sort_index()\n",
    "\n",
    "    def aggregate_modal_rankings(self, validator_name: str, aggregation_methods: List[RankingAggregationMethod], given_data_modality: str = None, invert=False): \n",
    "        rankings_df = self.construct_rankings_df(validator_name, given_data_modality=given_data_modality)\n",
    "        output_df = rankings_df.copy()\n",
    "        \n",
    "        for aggregation_method in aggregation_methods:\n",
    "            aggregation_method_name = aggregation_method.value\n",
    "            scorelist = self.convert_to_scorelist(rankings_df)\n",
    "            agg_method = getattr(RankingAggregator.FLRA, aggregation_method_name)\n",
    "            agg_rankings = agg_method(scorelist)[1]\n",
    "            output_df[f\"{aggregation_method_name}_agg_rank\"] = list(agg_rankings.values())\n",
    "\n",
    "        return output_df\n",
    "        \n",
    "    def aggregate_rankings(self, validator_name: str, aggregation_methods: List[RankingAggregationMethod]):\n",
    "        rankings_df = self.construct_rankings_df(validator_name)\n",
    "        output_df = rankings_df.copy()\n",
    "        \n",
    "        for aggregation_method in aggregation_methods:\n",
    "            aggregation_method_name = aggregation_method.value\n",
    "            scorelist = self.convert_to_scorelist(rankings_df)\n",
    "            agg_method = getattr(RankingAggregator.FLRA, aggregation_method_name)\n",
    "            agg_rankings = agg_method(scorelist)[1]\n",
    "\n",
    "            output_df[f\"{aggregation_method_name}_agg_rank\"] = list(agg_rankings.values()) \n",
    "\n",
    "        return output_df\n",
    "\n",
    "aggregator = RankingAggregator(results_object=results)\n",
    "input_df = aggregator.aggregate_modal_rankings(\"my_unsupervised_anomaly_data_validator\", [RankingAggregationMethod.LOWEST_RANK, RankingAggregationMethod.HIGHEST_RANK, RankingAggregationMethod.ROUND_ROBIN], given_data_modality=\"resnet50_backbone_mnist_image\")\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.show_datapoint(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
